{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d346cec7-89b3-4b94-b518-d83e6dd7ff2a",
   "metadata": {},
   "source": [
    "# Aircraft Surface Positioning Pipeline Demo\n",
    "\n",
    "- Dataset: Tufts univerity turf field\n",
    "- Pose estimations: Generated through COLMAP (Schonberger and Frahm, 2016)\n",
    "\n",
    "\n",
    "\n",
    "NOTES:\n",
    "- All 'Visualizer' steps are for visualization purposes only, can be commented out\n",
    "- Recommended to start with 5 local images, as solution with 10 images begins to drift (see paper for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f4383e-81af-40cb-a765-977430819130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel-choate/miniconda3/envs/py39/lib/python3.9/site-packages/dash/dash.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from groundNAV_agent import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323fcc8f-4a87-4b49-8925-d2d76d5b4893",
   "metadata": {},
   "source": [
    "## Input files: \n",
    "- SfM solution (3)\n",
    "    - Images\n",
    "    - Cameras\n",
    "    - 3D Cloud\n",
    "- Local Images for registration (10)\n",
    "- Satellite reference image (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f7ba4a-815f-4fab-a3d4-8c242e05c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SfM files \n",
    "images_colm = '../sample_data/SfM_soln/images.txt'\n",
    "cameras_colm = '../sample_data/SfM_soln/cameras.txt'\n",
    "pts3d_colm = '../sample_data/SfM_soln/points3D_f.txt'\n",
    "\n",
    "# Local images - folder\n",
    "# im_local = '../sample_data/local_imgs_10' # With 10 local images \n",
    "im_local = '../sample_data/local_imgs_5' # With 5 local images\n",
    "\n",
    "# Satellite reference image\n",
    "sat_ref = '../sample_data/TurfSat.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba3f487-df7f-4c72-b355-728fc9d02727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class \n",
    "gnav = gNAV_agent(images_colm, cameras_colm, pts3d_colm, im_local, sat_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064c7bc-1edd-4642-816c-3615e17e9fb2",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "### Visualizer (1)\n",
    "- Initial pose estimation and sparse point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0682f050-4623-492a-931c-01a3c20c3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the sparse scene and camera poses generated through SfM \n",
    "\n",
    "# vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window(window_name = \"Pose estimations and sparse cloud: SfM COORDINATES (not absolute)\")\n",
    "\n",
    "# gnav.pose_scene_visualization(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426871db-5743-4614-b94f-9fb5079edf9e",
   "metadata": {},
   "source": [
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8c694-3e72-445b-a2bc-dd7e77554087",
   "metadata": {},
   "source": [
    "## Set Reference Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9046b2f-429e-4aae-9148-1a7dcdefa344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference frame transformation\n",
      " [[-1.55069060e-03  9.81197008e-01  1.93002661e-01 -1.21025836e-01]\n",
      " [-1.42845166e-01 -1.91240997e-01  9.71093270e-01  1.86102525e+00]\n",
      " [ 9.89743833e-01 -2.60636319e-02  1.40455805e-01  7.28134156e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Set reference frame - transform to ground-parallel coordinate frame \n",
    "tform_ref_frame = gnav.set_ref_frame(gnav.pts_gnd_idx)\n",
    "tform_ref_frame_pts = gnav.inv_homog_transform(tform_ref_frame)\n",
    "print(\"\\nReference frame transformation\\n\", tform_ref_frame_pts)\n",
    "\n",
    "# Transfer all points to new coordinate system\n",
    "origin_ref, scene_pts_ref, scene_vec_ref = gnav.unit_vec_tform(gnav.scene_pts, gnav.origin_w, tform_ref_frame_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6bd9c-86fd-4200-b40a-5757928a8a5a",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "### Visualizer (2)\n",
    "\n",
    "- Sparse point cloud in NEW (ground-referenced) frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebf459c-5379-407c-a36b-3501fa55c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the sparse scene and camera poses generated through SfM \n",
    "\n",
    "# vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window(window_name = \"Sparse cloud: ground-reference coords\")\n",
    "\n",
    "# gnav.pose_scene_visualization_ref(vis, scene_pts_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671da132-461e-4f62-8424-659ab528dd51",
   "metadata": {},
   "source": [
    "__________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c5ab7-1e5e-4ee4-9f85-fcf937d9c68a",
   "metadata": {},
   "source": [
    "## Image Mosaic Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3b497a-7285-4c97-b998-3589e7371ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mosaic parameters - arbitrarily obtained, can be modified\n",
    "mosaic_params = np.load('../sample_data/GP_sections/mosaic_params.npy')\n",
    "# Grab specified image points from local images \n",
    "gnav.grab_image_pts_tot(mosaic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f9373-774e-4727-8fd5-c455f1c1528b",
   "metadata": {},
   "source": [
    "____________________________________________\n",
    "### Visualizer (3)\n",
    "\n",
    "- Ground plane sections from 2D image to be used for mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dfc3b45-8682-45fe-b671-1ff58cd0d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,8))\n",
    "# gnav.plot_gnd_pts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d791563-f535-4483-811e-84bfdaf77e28",
   "metadata": {},
   "source": [
    "_________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad740905-3b4a-48d0-b39d-fb5b4ab14895",
   "metadata": {},
   "source": [
    "## Image mosaic formulation stages \n",
    "1. Create unit vectors in camera coordinates\n",
    "2. Grab transformation matrix (camera to world (SfM) coords)\n",
    "3. Transform to world (SfM) coords\n",
    "4. Projection on ground plane\n",
    "5. Transform to ground-referenced plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb77f5f5-e7e6-4fac-8b35-dd398f38f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done image  0\n",
      "\n",
      "Done image  1\n",
      "\n",
      "Done image  2\n",
      "\n",
      "Done image  3\n",
      "\n",
      "Done image  4\n"
     ]
    }
   ],
   "source": [
    "# Generate projection of image sections \n",
    "for i in range(len(gnav.images_dict)):\n",
    "    # STEP 1: Unit vectors in camera coords \n",
    "    pts_vec_c, pts_rgb_gnd = gnav.unit_vec_c(i)\n",
    "    gnav.im_mosaic[i] = {'rgbc': pts_rgb_gnd}\n",
    "\n",
    "    # STEP 2: Transformation matrix moves from camera coords to world coords\n",
    "    id = gnav.im_ids[i]\n",
    "    homog_w2c, homog_c2w = gnav.get_pose_id(id,i)\n",
    "    # print('Homogeneous transformation from world to camera \\n', homog_c2w)\n",
    "    # print('\\n Homogeneous transformation from camera to world \\n', homog_w2c)\n",
    "\n",
    "    # STEP 3: Transform to world coords\n",
    "    origin_c, pts_loc_w, pts_vec_w = gnav.unit_vec_tform(pts_vec_c, gnav.origin_w, homog_c2w)\n",
    "    # print('\\n New camera frame origin = ', origin_c)\n",
    "    \n",
    "    # STEP 4: Get new points \n",
    "    ranges, new_pts_w = gnav.pt_range(pts_vec_w, homog_c2w, origin_c, i)\n",
    "    # print('\\nNew Points \\n', new_pts_w)\n",
    "\n",
    "    # STEP 5: Transfer points to reference frame\n",
    "    __, new_pts_r, pts_vec_r = gnav.unit_vec_tform(new_pts_w, gnav.origin_w, tform_ref_frame_pts)\n",
    "\n",
    "    # Convert points to grayscale \n",
    "    gray_c = gnav.conv_to_gray(gnav.im_mosaic[i]['rgbc'],i)\n",
    "    # print(gray_c)\n",
    "\n",
    "    # Put new points and grayscale colors in image mosaic\n",
    "    gnav.im_mosaic[i]['pts'] = new_pts_r\n",
    "    gnav.im_mosaic[i]['color_g'] = gray_c\n",
    "    \n",
    "    print(\"\\nDone image \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dada9cf-032d-49e2-a79d-e5c435b6bbbe",
   "metadata": {},
   "source": [
    "_____________________________________\n",
    "### Visualizer (4)\n",
    "\n",
    "- Image mosaic formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0edd112-da04-4ad6-8190-37a77046f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create visualization\n",
    "# vis = o3d.visualization.Visualizer()\n",
    "# vis.create_window(window_name=\"Image mosaic formulation\")\n",
    "\n",
    "# gnav.mosaic_visualization(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b4512-7ba4-4b61-b6f4-f9b76b7adf0f",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4cb87-17c6-472c-bdc8-f482eb08e4ae",
   "metadata": {},
   "source": [
    "## Implement initial guess\n",
    "\n",
    "- Initial guess to be fed into least squares process\n",
    "- Must be good enough to allow convergence\n",
    "\n",
    "### 4 DOF Solution\n",
    "\n",
    "The state equation includes the following variables:\n",
    "\n",
    "- **x**: position along the x-axis  \n",
    "- **y**: position along the y-axis  \n",
    "- **$\\boldsymbol{\\theta}$**: heading (yaw angle)\n",
    "- **s**: scale factor\n",
    "\n",
    "**State vector:**  \n",
    "$x = [x,\\ y,\\ \\theta, s]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f18c347-d432-45c1-97b3-34374276ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess parameters \n",
    "# 5 image solution\n",
    "scale, x, y, yaw = 80, -52, 20, np.deg2rad(140)\n",
    "\n",
    "tform_guess = gnav.tform_create(x,y,0,0,0,yaw)\n",
    "gnav.best_guess_tform = tform_guess\n",
    "gnav.best_guess_scale = scale\n",
    "\n",
    "# Implement\n",
    "gnav.implement_guess(gnav.best_guess_tform, gnav.best_guess_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f8f2a-116a-43b8-9fe3-99c45c370242",
   "metadata": {},
   "source": [
    "__________________________________________________\n",
    "### Visualizer (5)\n",
    "\n",
    "- Mosaic with reference satellite map (with initial guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7a511f-9286-4c9e-a5ca-e9c835f6e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libGL: Can't open configuration file /etc/drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /home/daniel-choate/.drirc: No such file or directory.\n",
      "using driver i915 for 73\n",
      "libGL: Can't open configuration file /etc/drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /home/daniel-choate/.drirc: No such file or directory.\n",
      "using driver i915 for 73\n",
      "pci id for fd 73: 8086:a7a0, driver iris\n",
      "libGL: Can't open configuration file /etc/drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /home/daniel-choate/.drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /etc/drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /home/daniel-choate/.drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /etc/drirc: No such file or directory.\n",
      "libGL: Can't open configuration file /home/daniel-choate/.drirc: No such file or directory.\n",
      "Using DRI3 for screen 0\n"
     ]
    }
   ],
   "source": [
    "# Create visualization\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"Image mosaic with reference map (initial guess)\")\n",
    "\n",
    "gnav.mosaic_w_ref_visualization(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5949be-aed5-4e89-aa1f-f359e15d523f",
   "metadata": {},
   "source": [
    "_________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89454fbf-033d-4170-b944-5ea30c7111e0",
   "metadata": {},
   "source": [
    "## Least squares optimization\n",
    "\n",
    "### SSD measurements\n",
    "- A sum of squared differences (SSD) of intensities is used as a residual measurement for the least squares optimization \n",
    "- Based on pixel shifts of an nxn grid (see paper)\n",
    "- Default n = 5: balancing runtime and accuracy\n",
    "\n",
    "### Convergence\n",
    "- See paper for jacobian construction details\n",
    "- Note: different initial guesses will require varied amounts of iterations to reach convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bfa894-8cef-4204-b797-56fd76ced151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
